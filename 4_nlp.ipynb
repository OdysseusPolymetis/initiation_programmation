{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/OdysseusPolymetis/initiation_programmation/blob/main/4_nlp.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Quelques expériences de traitement automatique de la langue (NLP)**"
      ],
      "metadata": {
        "id": "8PULb8IzAbRW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "On va commencer par prendre des textes qui sont sur le github, qui sont extraits de Frantext."
      ],
      "metadata": {
        "id": "5LPACy73Arb2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hmgsJihi9oyn"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/OdysseusPolymetis/initiation_programmation.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4odmVjyBCQKm"
      },
      "outputs": [],
      "source": [
        "!unzip '/content/initiation_programmation/auteurs.zip'"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "On va ici devoir importer les modules nécessaires. Copiez la cellule qui suit.\n",
        "```python\n",
        "import os\n",
        "import xml.etree.ElementTree as ET\n",
        "import string\n",
        "```"
      ],
      "metadata": {
        "id": "CLVYiWclA0hV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1zc7AeOuCeu9"
      },
      "outputs": [],
      "source": [
        "# collez la cellule ci-dessus"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Vous allez ensuite ajouter un fichier qui contient une liste de mots outils.\n",
        "```python\n",
        "stopwords = open(\"/content/initiation_programmation/stopwords_fr.txt\",'r',encoding=\"utf8\").read().split(\"\\n\")\n",
        "```"
      ],
      "metadata": {
        "id": "hVx3rdBjBED3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TeisTyOLCvSS"
      },
      "outputs": [],
      "source": [
        "# collez la cellule ci-dessus"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "On va ensuite vouloir voir combien de mots sont dans le fichier. Utilisez la fonction `len(votreListe)`."
      ],
      "metadata": {
        "id": "lMt2mYQDBUjl"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1vyk0M9jLfQy"
      },
      "outputs": [],
      "source": [
        "# montrez la longueur de la liste"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "On va ensuite pointer vers l'endroit où se trouvent les fichiers. Si vous voulez prendre un autre auteur, vous pouvez juste changer le nom du dossier final.\n",
        "```python\n",
        "french_dir = '/content/auteurs/verne'\n",
        "```"
      ],
      "metadata": {
        "id": "nfjEcFCtBlho"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2Nn0eqitDsbJ"
      },
      "outputs": [],
      "source": [
        "# collez la cellule ci-dessus"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "La cellule qui suit est plus compliquée, mais essayez de comprendre, et dans la cellule qui suivra, essayez de l'expliquer basiquement."
      ],
      "metadata": {
        "id": "KmnTKduKCEAa"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5Cng7tIAEqEW"
      },
      "outputs": [],
      "source": [
        "def process_gold_directory(directory):\n",
        "    all_sentences = []\n",
        "\n",
        "    for root, dirs, files in os.walk(directory):\n",
        "        for file in files:\n",
        "            file_path = os.path.join(root, file)\n",
        "            sentences = parse_treebank_file(file_path)\n",
        "\n",
        "            for sentence in sentences:\n",
        "                all_sentences.append(sentence)\n",
        "\n",
        "    return all_sentences"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# essayez d'expliquer en commentaire la cellule qui précède.\n",
        "#\n",
        "#\n",
        "#"
      ],
      "metadata": {
        "id": "Ov7aS_7VCLs5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "La suivante, c'est moi qui vais vous l'expliquer en gros. Mais n'oubliez pas de l'exécuter."
      ],
      "metadata": {
        "id": "czUTrrULCTjE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NVOJGmNEDyYh"
      },
      "outputs": [],
      "source": [
        "def parse_treebank_file(file_path):\n",
        "\n",
        "    namespaces = {\n",
        "        'tei': 'http://www.tei-c.org/ns/1.0',\n",
        "        'x': 'http://www.atilf.fr/allegro'\n",
        "    }\n",
        "\n",
        "    tree = ET.parse(file_path)\n",
        "    root = tree.getroot()\n",
        "\n",
        "    indexed_gold_sentences = []\n",
        "    file_id1 = os.path.basename(file_path)\n",
        "\n",
        "    for i, sentence in enumerate(root.findall('.//tei:p', namespaces)):\n",
        "        words = []\n",
        "        for word in sentence.findall('.//x:wf', namespaces):\n",
        "          word_text = word.get('word')\n",
        "          lemma_text = word.get('lemma')\n",
        "          if not any(entity in word_text or entity in lemma_text for entity in ['&quot;', '&amp;quot;']):\n",
        "                words.append({\n",
        "                    'form': word_text,\n",
        "                    'lemma': lemma_text,\n",
        "                    'pos': word.get('pos')\n",
        "                })\n",
        "        indexed_gold_sentences.append(words)\n",
        "    return indexed_gold_sentences"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Que fait la cellule qui suit selon vous ?"
      ],
      "metadata": {
        "id": "n1H_m9FCCatk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xptt-HryESPP"
      },
      "outputs": [],
      "source": [
        "treebank_sentences=process_gold_directory(french_dir)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ici j'aimerais que vous vérifiez la longueur de la variable `treebank_sentences`."
      ],
      "metadata": {
        "id": "aj6GmsvCCfp9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PnYMxlvsYiDl"
      },
      "outputs": [],
      "source": [
        "# vérifiez la longueur de la variable."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Maintenant, essayez d'expliquer la cellule qui suit."
      ],
      "metadata": {
        "id": "bYYP-Ow5CryO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ozm-e8aGEgo8"
      },
      "outputs": [],
      "source": [
        "forms=[]\n",
        "lemmas=[]\n",
        "no_stop=[]\n",
        "\n",
        "for sentence in treebank_sentences:\n",
        "  for word in sentence:\n",
        "    if word[\"form\"] not in string.punctuation and word[\"lemma\"] not in stopwords:\n",
        "      if word[\"lemma\"] is not None:\n",
        "        lemmas.append(word[\"lemma\"])\n",
        "        no_stop.append(word[\"lemma\"])\n",
        "      forms.append(word[\"form\"])\n",
        "    elif word[\"form\"] not in string.punctuation:\n",
        "      if word[\"lemma\"] is not None:\n",
        "        lemmas.append(word[\"lemma\"])\n",
        "      forms.append(word[\"form\"])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Essayez d'expliquer la cellule qui précède.\n",
        "#\n",
        "#\n",
        "#"
      ],
      "metadata": {
        "id": "0JKW0qnRCwRy"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Voyons maintenant la longueur de chaque liste."
      ],
      "metadata": {
        "id": "Mj4IYl6NDFCX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yYraq6-PFkVt"
      },
      "outputs": [],
      "source": [
        "len(lemmas)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pnybwPZvFmmL"
      },
      "outputs": [],
      "source": [
        "len(forms)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tKhkW-QAKmE8"
      },
      "outputs": [],
      "source": [
        "len(no_stop)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3F5Qv3JEKsVd"
      },
      "source": [
        "##Le TAL, qu'est-ce, et pourquoi ?\n",
        "En termes généraux, beaucoup de gens ont recours au TAL pour la phase de prétraitement. Et c'est un passage bien souvent nécessaire si vous voulez éviter le pbruit dans les données, notamment sur le plan fréquentiel.\n",
        "<br>Ici nous allons voir un exemple d'analyse fréquentielle avec et sans prétraitement."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nZfr-3OFKv9z"
      },
      "source": [
        "Imaginons que nous voulions créer un nuage de mots pour représenter un texte particulier.\n",
        "<br>Ici nous allons nous concentrer sur toutes les oeuvres de Jules Verne (mais vous pouvez en choisir un autre) en même temps, en les prenant sur Frantext."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bcv7G8nKKoBW"
      },
      "outputs": [],
      "source": [
        "from wordcloud import WordCloud\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "def create_word_cloud(words_list, title):\n",
        "    text = ' '.join(words_list)\n",
        "\n",
        "    radius = 495\n",
        "    diameter = radius * 2\n",
        "    center = radius\n",
        "    x, y = np.ogrid[:diameter, :diameter]\n",
        "    mask = (x - center) ** 2 + (y - center) ** 2 > radius ** 2\n",
        "    mask = 255 * mask.astype(int)\n",
        "\n",
        "    mask_rgba = np.dstack((mask, mask, mask, 255 - mask))\n",
        "\n",
        "    wordcloud = WordCloud(repeat=False, width=diameter, height=diameter,\n",
        "                          background_color=None, mode=\"RGBA\", colormap='plasma',\n",
        "                          mask=mask_rgba).generate(text)\n",
        "\n",
        "    plt.figure(figsize=(10, 10))\n",
        "    plt.imshow(wordcloud, interpolation='bilinear')\n",
        "    plt.title(title)\n",
        "    plt.axis('off')\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DxGhouXpK7uF"
      },
      "outputs": [],
      "source": [
        "create_word_cloud(forms, 'Word Cloud for Forms')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cYmIG0iOLH9m"
      },
      "source": [
        "Ce nuage ne sert pas à grand chose. Pourquoi ? Parce qu'il nous permet simplement de dire que le grec contient bon nombre de mots outils. Et sauf dans le cas d'une analyse stylistique, pour une représentation graphique, cela n'a guère de poids. Par ailleurs, bon nombre de mots sont encore sous leur forme flexionnelle : on a donc autant d'occurrences que de mots conjugués par exemple.\n",
        "<br>Donc, **lemmatisons**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s-4ReHVhK_3C"
      },
      "outputs": [],
      "source": [
        "create_word_cloud(lemmas, 'Word Cloud for Lemmas')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZuejmhbjLVlZ"
      },
      "source": [
        "Ça n'est pas beaucoup mieux, mais c'est mieux. Certains termes commencent à émerger.\n",
        "<br>Cette fois, enlevons les **mots-outils**, et la ponctuation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jdG07R8sLNDJ"
      },
      "outputs": [],
      "source": [
        "create_word_cloud(no_stop, 'Word Cloud for Lemmas without stopwords')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9vBMRwxhUnth"
      },
      "source": [
        "Clairement il s'agit d'un nuage beaucoup plus satisfaisant désormais."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "euYgHuJYUtsL"
      },
      "source": [
        "#**TOKÉNISER, LEMMATISER, POSTAGGER**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Umc_maNTUwy_"
      },
      "source": [
        "Maintenant essayons **`stanza`**.\n",
        "<br>Nous allons reprendre l'_Avare_. Il est déjà présent dans le github que vous avez téléchargé au début de ce notebook."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0hqDxVdeLWqN"
      },
      "outputs": [],
      "source": [
        "!pip install stanza"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_T6KT4SLVErE"
      },
      "outputs": [],
      "source": [
        "filepath_of_text = \"/content/initiation_programmation/l_avare.txt\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zlVKP4tSVLjQ"
      },
      "outputs": [],
      "source": [
        "full_text = open(filepath_of_text, encoding=\"utf-8\").read()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZF3DbB0lVRae"
      },
      "source": [
        "##**stanza**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VyeDuCyZVSV6"
      },
      "source": [
        "J'utilise généralement `stanza` pour trois raisons :\n",
        "<br>- il y a un très grand nombre de langues traitées (Vous pouvez les consulter [ici](https://stanfordnlp.github.io/stanza/performance.html)),\n",
        "<br>- c'est très rapide et ça fait un excellent usage de la GPU,\n",
        "<br>- c'est facile à implémenter."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0C8s7GSPVXB3"
      },
      "source": [
        "Pour télécharger des modèles spécifiques dans `stanza`, vous devrez rentrer les codes lettres des langues, que vous trouverez [ici](https://stanfordnlp.github.io/stanza/performance.html).\n",
        "<br>Commençons avec le modèle français par défaut."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LJkUMgR0VOm9"
      },
      "outputs": [],
      "source": [
        "import stanza\n",
        "stanza.download('fr')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XFsfgJtjVmOk"
      },
      "source": [
        "Beaucoup de modèles ont beaucoup de processus embarqués, et sont trop lourds. Je vous recommande d'être plus sélectifs lors de l'instanciation des processus. Vous pouvez le faire de cette manière :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5ozKbOZDVcfq"
      },
      "outputs": [],
      "source": [
        "nlp_stanza = stanza.Pipeline(lang='fr', processors='tokenize,mwt,pos,lemma')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xHBRGwTGVtUx"
      },
      "outputs": [],
      "source": [
        "def batch_process(text, nlp, batch_size=50):\n",
        "    paragraphs = text.split('\\n')\n",
        "    batches = [paragraphs[i:i + batch_size] for i in range(0, len(paragraphs), batch_size)]\n",
        "\n",
        "    words = []\n",
        "\n",
        "    for batch in batches:\n",
        "        batch_text = '\\n'.join(batch)\n",
        "        doc = nlp(batch_text)\n",
        "        for sentence in doc.sentences:\n",
        "            for word in sentence.words:\n",
        "                token={}\n",
        "                if word.lemma is not None:\n",
        "                    token[\"word\"]=word.text\n",
        "                    token[\"lemma\"]=word.lemma\n",
        "                    token[\"pos\"]=word.pos\n",
        "                    words.append(token)\n",
        "\n",
        "    return words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a1JNXa73Xk78"
      },
      "outputs": [],
      "source": [
        "avare_analyzed = batch_process(full_text, nlp_stanza)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6PY_dQJ_XuPa"
      },
      "outputs": [],
      "source": [
        "print(avare_analyzed[15:20])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LzujisfQanhj"
      },
      "source": [
        "## Les word embeddings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NlyffyCXbc_L"
      },
      "source": [
        "D'abord on va récupérer le traitement qu'on avait fait plus haut sur les textes de Verne. On va simplement retenir des listes de phrases, qui sont elles-mêmes des listes de mots."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bw6ELMRAaRb7"
      },
      "outputs": [],
      "source": [
        "def convert_to_lemmas_sentences(indexed_gold_sentences):\n",
        "    lemmas_sentences = []\n",
        "\n",
        "    for sentence in indexed_gold_sentences:\n",
        "        sent = list()\n",
        "        for word in sentence:\n",
        "            sent.append(word['lemma'])\n",
        "            if word['lemma'] in [\".\",\"?\",\"!\"]:\n",
        "                lemmas_sentences.append(sent)\n",
        "                sent = list()\n",
        "\n",
        "    return lemmas_sentences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u6wmkUWIbt4g"
      },
      "outputs": [],
      "source": [
        "lemmas_sentences = convert_to_lemmas_sentences(treebank_sentences)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C432Inpzb8jN"
      },
      "outputs": [],
      "source": [
        "len(lemmas_sentences)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dyHXsANnf6HW"
      },
      "outputs": [],
      "source": [
        "lemmas_sentences[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Huc08oCvcJJp"
      },
      "source": [
        "On va ensuite importer un vectoriseur. Ici Word2vec."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-sWftmV9cA6u"
      },
      "outputs": [],
      "source": [
        "from gensim.models import Word2Vec"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "tLQXI1nMcNeQ"
      },
      "outputs": [],
      "source": [
        "model = Word2Vec(lemmas_sentences, min_count=2, max_vocab_size=10000, negative=10, epochs=100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "LqMwFKEHcVPv"
      },
      "outputs": [],
      "source": [
        "model.wv.save(\"/content/model_verne.bin\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "YBJRUdxxchwj"
      },
      "outputs": [],
      "source": [
        "#Paris is to France what London is to what ? model.wv.most_similar(positive=['Londres', 'France'], negative=['Paris'],topn=5)\n",
        "#King is to man what Queen is to what ? model.wv.most_similar(positive=['reine', 'homme'], negative=['roi'],topn=5)\n",
        "model.wv.most_similar(positive=['femme', 'capitaine'], negative=['homme'],topn=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DKHvyCILckb2"
      },
      "outputs": [],
      "source": [
        "model.wv.most_similar('science',topn=10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o9PskxePd2PH"
      },
      "source": [
        "Et pour une visualisation plus globale de vos résultats, vous pouvez utiliser les fichiers que nous générons ci-dessous dans [tensorflow](https://projector.tensorflow.org/)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OKSFpXFAc-WI"
      },
      "outputs": [],
      "source": [
        "with open('/content/tensorflow.tsv', 'w+') as tensors:\n",
        "    with open( '/content/tensorflowmeta.tsv', 'w+') as metadata:\n",
        "         for word in model.wv.index_to_key:\n",
        "                metadata.write(word+'\\n')\n",
        "                vector_row = '\\t'.join(map(str, model.wv[word]))\n",
        "                tensors.write(vector_row + '\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jDKZdcjHdkEf"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "authorship_tag": "ABX9TyMzFAzikFrrSA8eS8CqruXz",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}